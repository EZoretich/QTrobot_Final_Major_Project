#!/usr/bin/env python

# --------------------- QTROBOT PLAYING XYLOPHONE
# ----------- This script is the final version of my final major project's code, with simple GUI implemented.
# ----------- The main purpose of the script is to give users the option to choose teh desired Music Mode.
# ----------- The first mode allows QTrobot to play a pre-established melody, through the use of dictionaries.
# ----------- The second Mode will give the users a 15 seconds window to play a short melody, after which 
# ----------- thanks to the use of audio signal processing and a trained machine learning model, each played note
# ----------- will be detected and labelled. The prediction is then linked to QTrobot's kinematic, which will
# ----------- allow it to recreate the melody.

#------------------------------------------------------------------------ IMPORTS

import rospy
import time
from musi_care.srv import qt_command
#from qt_robot_interface.srv import * #so we can use the qt service srvs
#from qt_gesture_controller.srv import * # #so we can use the service srv "gesture_play" 
from qt_motors_controller.srv import *
from std_msgs.msg import String #so we can become a publisher and publish a string to the QT node that handles tts.
from std_msgs.msg import Bool
from sensor_msgs.msg import JointState
import librosa
import librosa.display
import pyaudio
import wave
import numpy as np
from matplotlib import pyplot as plt
from glob import glob
import soundfile as sf
import joblib
from sklearn.neighbors import KNeighborsClassifier
import csv
rospy.init_node('QT_Xylophone')

# ---------- Variable storing QT's joints' position (for state_callback)

right_shoulder_pitch_pos = 0
right_shoulder_roll_pos = 0
right_elbow_roll_pos = 0
left_shoulder_pitch_pos = 0
left_shoulder_roll_pos = 0
left_elbow_roll_pos = 0

# --------------------------------------------------------------------- FUNCTIONS

# ---------- "State_Callback" is used to obtain the position of joints' motors.
# ---------- The topic's messages for each specific motor in each joint is extracted
# ---------- and will be used to check the real position of QTroobot's motors.

def state_callback(msg):
    global right_shoulder_pitch_pos
    global right_shoulder_roll_pos
    global right_elbow_roll_pos
    global left_shoulder_pitch_pos
    global left_shoulder_roll_pos
    global left_elbow_roll_pos
    
    # Right Arm Joints
    right_shoulder_pitch_pos = msg.position[msg.name.index("RightShoulderPitch")]
    right_shoulder_roll_pos = msg.position[msg.name.index("RightShoulderRoll")]
    right_elbow_roll_pos = msg.position[msg.name.index("RightElbowRoll")]
    
    # Left Arm Joints
    left_shoulder_pitch_pos = msg.position[msg.name.index("LeftShoulderPitch")]
    left_shoulder_roll_pos = msg.position[msg.name.index("LeftShoulderRoll")]
    left_elbow_roll_pos = msg.position[msg.name.index("LeftElbowRoll")]
    


rospy.Subscriber('/qt_robot/joints/state', JointState, state_callback)


# ---------- "Change Motor Speed" is used to change the velocity at which Qt's motors operate.
# ---------- The function takes the desired speed percentage, and through appropriate message formatting
# ---------- send the new values to QT's service designed to change all motor's velocity.

def change_mot_speed(speed_percent):
	action_type = "velocity"
	action_content = speed_percent
	command_blocking = False

	rospy.wait_for_service('/qt_command_service')
	command_controller = rospy.ServiceProxy('/qt_command_service', qt_command)
	#command_complete = command_controller(action_type, action_content, command_blocking)

	#print(command_complete)


# ----------- "Get Ready" is used to send QTrobot's to a specific position before starting to play teh xylohpone notes
# ---------- The function includes three movements, to create more visually pleasing movements, as well as ensure that
# ---------- Qt's arms are not hitting the xylophone holder. For each of the three action, a message including the arm we
# ---------- wish to move and its' motors new location will be send to QT's main node, allowing it to move.

def get_ready(arm, move_1, move_2, move_3):

	print("----- GET READY -----")
	start = rospy.get_time() # ---- Start Timing
	action_type = arm
	action_content = move_1
	command_blocking = False

	rospy.wait_for_service('/qt_command_service')
	command_controller = rospy.ServiceProxy('/qt_command_service', qt_command)
	command_complete = command_controller(action_type, action_content, command_blocking)
	rospy.sleep(0.1)

	print(command_complete)
	finish = rospy.get_time() # ----- Stop Timing
	elapsed = round((finish - start), 3) # ----- Calculate Time Elapsed
	print(elapsed, "   Sec.")
	print("----------", action_type, "----------")
	print("DESIRED POS:	", action_content)
	if action_type == "right_arm":
	    actual_pos = [right_shoulder_pitch_pos, right_shoulder_roll_pos, right_elbow_roll_pos]
	    print("REAL POS:	", actual_pos)
	else:
	    actual_pos = [left_shoulder_pitch_pos, left_shoulder_roll_pos, left_elbow_roll_pos]
	    print("REAL POS:	", actual_pos)
	    
	#rospy.sleep(0.1)
	
	# ------------------------------------------------------------------------
	start = rospy.get_time() # ----- Start Timing
	action_type = arm
	action_content = move_2
	command_blocking = False

	rospy.wait_for_service('/qt_command_service')
	command_controller = rospy.ServiceProxy('/qt_command_service', qt_command)
	command_complete = command_controller(action_type, action_content, command_blocking)
	rospy.sleep(0.1)
	print(command_complete)
	finish = rospy.get_time() # ----- Stop Timing
	elapsed = round((finish - start), 3) # ----- Calculate Time Elapsed
	print(elapsed, "   Sec.")
	print("----------", action_type, "----------")
	print("DESIRED POS:	", action_content)
	if action_type == "right_arm":
	    actual_pos = [right_shoulder_pitch_pos, right_shoulder_roll_pos, right_elbow_roll_pos]
	    print("REAL POS:	", actual_pos)
	else:
	    actual_pos = [left_shoulder_pitch_pos, left_shoulder_roll_pos, left_elbow_roll_pos]
	    print("REAL POS:	", actual_pos)
	    
	#rospy.sleep(0.1)
	
	# ------------------------------------------------------------------------
	start = rospy.get_time() # ----- Start Timing
	action_type = arm
	action_content = move_3
	command_blocking = False

	rospy.wait_for_service('/qt_command_service')
	command_controller = rospy.ServiceProxy('/qt_command_service', qt_command)
	command_complete = command_controller(action_type, action_content, command_blocking)
	rospy.sleep(0.1)
	print(command_complete)
	finish = rospy.get_time() # ----- Stop Timing
	elapsed = round((finish - start), 3) # ----- Calculate Time Elapsed
	print(elapsed, "   Sec.")
	print("----------", action_type, "----------")
	print("DESIRED POS:	", action_content)
	if action_type == "right_arm":
	    actual_pos = [right_shoulder_pitch_pos, right_shoulder_roll_pos, right_elbow_roll_pos]
	    print("REAL POS:	", actual_pos)
	else:
	    actual_pos = [left_shoulder_pitch_pos, left_shoulder_roll_pos, left_elbow_roll_pos]
	    print("REAL POS:	", actual_pos)
	    
	#rospy.sleep(3)

# ---------- "Play Note" function will allows QTrobot to play a note. It works similarly to the "Get Ready" function, where
# ---------- string types messages stating the arm we wish to move and the new position of the motors is sent to the main node
# ---------- allowing QT to move. This function perform as well three movements, although the two functions have been separated,
# ---------- as 'Play Note' only takes two positional argument (key and offset) instead of three.

def play_note(arm, key, offset):
	
	print("----- PLAY NOTE -----")
	actual_pos = [right_shoulder_pitch_pos, right_shoulder_roll_pos, right_elbow_roll_pos]
        # ---------- OFFSET
	start = rospy.get_time() # ----- Start Timing
	action_type = arm
	action_content = offset
	command_blocking = False
	print(key)

	rospy.wait_for_service('/qt_command_service')
	command_controller = rospy.ServiceProxy('/qt_command_service', qt_command)
	command_complete = command_controller(action_type, action_content, command_blocking)
	rospy.sleep(0.1)
	#check_pos(actual_pos,  action_content)
	print(command_complete)
	finish = rospy.get_time() # ----- Stop Timing
	elapsed = round((finish - start), 3) # ----- Calculate Time Elapsed
	print(elapsed, "   Sec.")
	print("----------", action_type, "----------")
	print("DESIRED POS:	", action_content)
	if action_type == "right_arm":
	    actual_pos = [right_shoulder_pitch_pos, right_shoulder_roll_pos, right_elbow_roll_pos]
	    print("REAL POS:	", actual_pos)
	    #print("RIGHT_S_PITCH:	", right_shoulder_pitch_pos)
	    #print("RIGHT_S_ROLL:	", right_shoulder_roll_pos)
	    #print("RIGHT_E_ROLL:	", right_elbow_roll_pos)
	else:
	    actual_pos = [left_shoulder_pitch_pos, left_shoulder_roll_pos, left_elbow_roll_pos]
	    print("REAL POS:	", actual_pos)
	    #print("LEFT_S_PITCH:	", left_shoulder_pitch_pos)
	    #print("LEFT_S_ROLL:	", left_shoulder_roll_pos)
	    #print("LEFT_E_ROLL:	", left_elbow_roll_pos)
	    
	#rospy.sleep(2)
	
	# ---------- NOTE
	start = rospy.get_time() # ----- Start Timing
	action_type = arm
	action_content = key
	command_blocking = False

	rospy.wait_for_service('/qt_command_service')
	command_controller = rospy.ServiceProxy('/qt_command_service', qt_command)
	command_complete = command_controller(action_type, action_content, command_blocking)
	rospy.sleep(0.1)
	#check_pos(actual_pos,  action_content)
	print(command_complete)
	finish = rospy.get_time() # ----- Stop Timing
	elapsed = round((finish - start), 3) # ----- Calculate Time Elapsed
	print(elapsed, "   Sec.")
	print("----------", action_type, "----------")
	print("DESIRED POS:	", action_content)
	if action_type == "right_arm":
	    actual_pos = [right_shoulder_pitch_pos, right_shoulder_roll_pos, right_elbow_roll_pos]
	    print("REAL POS:	", actual_pos)
	else:
	    actual_pos = [left_shoulder_pitch_pos, left_shoulder_roll_pos, left_elbow_roll_pos]
	    print("REAL POS:	", actual_pos)
	
	#rospy.sleep(2)
	# ---------- OFFSET 
	start = rospy.get_time() # ----- Start Timing
	action_type = arm
	action_content = offset
	command_blocking = False

	rospy.wait_for_service('/qt_command_service')
	command_controller = rospy.ServiceProxy('/qt_command_service', qt_command)
	command_complete = command_controller(action_type, action_content, command_blocking)
	rospy.sleep(0.1)
        
	#check_pos(actual_pos,  action_content)
	#check_pos(actual_pos, offset)
	finish = rospy.get_time() # ----- Stop Timing
	elapsed = round((finish - start), 3) # ----- Calculate Time Elapsed
	print(elapsed, "   Sec.")
	print(command_complete)
	print("----------", action_type, "----------")
	print("DESIRED POS:	", action_content)
	if action_type == "right_arm":
	    actual_pos = [right_shoulder_pitch_pos, right_shoulder_roll_pos, right_elbow_roll_pos]
	    print("REAL POS:	", actual_pos)
	else:
	    actual_pos = [left_shoulder_pitch_pos, left_shoulder_roll_pos, left_elbow_roll_pos]
	    print("REAL POS:	", actual_pos)
	    
	#rospy.sleep(2)

# ----------- "Go Home" function is used to sent QTrobot back to a 'home' position.
# ----------- It work similarly to the 'Get Ready' function, although only one movement is performed.

def go_home(arm, pose):
	start = rospy.get_time() # ----- Start Timing
	action_type = arm
	action_content = pose
	command_blocking = False

	rospy.wait_for_service('/qt_command_service')
	command_controller = rospy.ServiceProxy('/qt_command_service', qt_command)
	command_complete = command_controller(action_type, action_content, command_blocking)
	rospy.sleep(0.1)
	print(command_complete)
	finish = rospy.get_time() # ----- Stop Timing
	elapsed = round((finish - start), 3) # ----- Calculate Time Elapsed
	print(elapsed, "   Sec.")
	print("----------", action_type, "----------")
	print("DESIRED POS:	", action_content)
	if action_type == "right_arm":
	    actual_pos = [right_shoulder_pitch_pos, right_shoulder_roll_pos, right_elbow_roll_pos]
	    print("REAL POS:	", actual_pos)
	else:
	    actual_pos = [left_shoulder_pitch_pos, left_shoulder_roll_pos, left_elbow_roll_pos]
	    print("REAL POS:	", actual_pos)


# -------------------------- PLAY SONG FROM DICTIONARY (MUSIC SCRIPT)
# ----------- This function alows QTrobot to play a pre-established song, by passing as argument a dictionary
# ----------- storing the note and the duration of said notes.
# ----------- The function compares the time passed since it has been called, with the duration of the upcoming note, stored as
# ----------- the dictionary's key, allowing a representation of music tempo for short and long notes.
# ----------- The note to play is stored as a string in the dictionary's values.
# ----------- The function check which arm should be moved, based on the note label, then iterated though a main dictionary
# ----------- storing each of the available keys and their offset, allowing the appropriate movements for the upcoming note/offset.

def play_from_script(dictionary, notes_dict):
    start = time.time() #rospy.time()
    for duration, note in dictionary.items():
        if note:
            duration -= (time.time() - start)
            if duration > 0:
                time.sleep(duration)
            if note[0] in ["C_First_Inv", "B", "A", "G"]: # if note[0] in ["C_FI", "B", "A", "G"]:
                play_note('right_arm', notes_dict[note[0]], notes_dict[note[1]])
            else:
                play_note('left_arm', notes_dict[note[0]], notes_dict[note[1]])


# --------------------------- RECORD USER MELODY
# ----------- "Record Melody" is used to initiate the microphone stream. The function set specific parameters for
# ----------- the recording, such as format and sampling rate, initiate the stream to allow the recording of the user's melody
# ----------- by the use of PyAudio, then saves the recording caputre with the python library Wave. The funtion takes as argument
# ----------- the desired duration of melody to record

def record_melody(rec_length):
	CHUNK = 1024
	FORMAT = pyaudio.paInt16
	CHANNELS = 1
	RATE = 22050 #44100

	p =pyaudio.PyAudio()

	stream = p.open(format=FORMAT,
		        channels=CHANNELS,
		        rate=RATE,
		        input=True,
		        frames_per_buffer=CHUNK)

	print("Start Recording ...")
	frames = []
	seconds = rec_length
	for i in range(0, int(RATE/ CHUNK * seconds)):
	    data = stream.read(CHUNK)
	    frames.append(data)

	print("Recording Stopped.")
	stream.stop_stream()
	stream.close()
	p.terminate()


	wf = wave.open("User_Melody.wav", 'wb')
	wf.setnchannels(CHANNELS)
	wf.setsampwidth(p.get_sample_size(FORMAT))
	wf.setframerate(RATE)
	wf.writeframes(b''.join(frames))
	wf.close()

# --------------------------- SLICE MELODY BY NOTE DETECTED
# ----------- "Trim Song By Notes" allows the slicing of the user melody into the played notes.
# ----------- The function takes as argument the melody's raw format, their STFT conversion to dB and a list used
# ----------- to store the returned trimmed samples. To split the melody by notes, first it created a onset strenght envelope of the audio
# ----------- file, and uses a peak detection function to detect the notes (hence peaks in amplitude).
# ----------- It then uses the list on indexes returned and a proportion to trimeed the detected note from the original audio.
# ----------- The trimmed samples retuned by this function will be used as data to create a note predicion.

def trim_song_by_notes(raw, note_db, trim_samples):
    onset_env = librosa.onset.onset_strength(y = raw, sr=sr, S = note_db)
    peaks = librosa.util.peak_pick(onset_env,pre_max=2, post_max=2, pre_avg=3, post_avg=5, delta=3.0, wait=10)


    #print(len(raw)) #340452
    #print(peaks) #[ 45 119 192 264 337 406 478 554]
    #print(len(onset_env)) #665
    peaks_raw = []

    env_len = len(onset_env)
    raw_len = len(raw)
    for p in peaks:
        prop = round((p*raw_len)/env_len) - 1000 # - 1000 because without, it trims out part of the next note/begin of same note
        peaks_raw.append(prop)
    print(peaks_raw)

    for i in range(len(peaks_raw) - 1):
        start = peaks_raw[i]
        end = peaks_raw[i+1]
        print(start, end)
        segment = raw[start:end]
        #plot_wave(segment)
        trim_samples.append(segment)

    # Add the last segment (from the last peak to the end of the array)
    trim_samples.append(raw[peaks_raw[-1]:])
    #plot_wave(raw)
    return trim_samples

# ---------------------------------------------- VARIABLES

#--------------------- MOTOR ANGLES TO HIT KEYS

# Home Position (valid for both hands)
Home_r = "[43.0, -21.5, -48.900001525878906]"
Home_l = "[-43.0, -21.5, -48.900001525878906]"


#---------------------------------------- RIGHT ARM ----------------------------------------
# ------------------- Sending right arm to 'Get Ready' position
r_pose1 = "[-56.29999923706055, -26.700000762939453, 0.6000000238418579]"
r_pose2 = "[60.599998474121094, -26.399999618530273, 0.6000000238418579]"
r_pose3 = "[33.900001525878906, -26.399999618530273, -73.5999984741211]"


# ---------------------------------------- LEFT ARM ----------------------------------------
# ------------------- Sending left arm to 'Get Ready' position
l_pose1 = "[56.29999923706055, -26.700000762939453, 0.6000000238418579]"
l_pose2 = "[-60.599998474121094, -26.399999618530273, 0.6000000238418579]"
l_pose3 = "[-33.900001525878906, -26.399999618530273, -73.5999984741211]"


#---------------------------------------NOTES & OFFSETS -------------------------------------
# ----- notes added also as separate variables. CHANGE, DEPENDING ON WHAT TO DO WITH MIC/RECOGNITION ISSUES IN LINUX
'''
offset_C_First_Inv = "[27.600000381469727, -51.5, -43.29999923706055]" #55
C_First_Inv = "[17.600000381469727, -51.5, -43.29999923706055]"
offset_B = "[26.299999237060547, -59.0, -42.70000076293945]" # 54
B = "[16.299999237060547, -59.0, -42.70000076293945]"
offset_A = "[25.300000190734863, -75.9000015258789, -28.0]" #46
A = "[15.300000190734863, -75.9000015258789, -28.0]"
offset_G = "[25.899999618530273, -84.4000015258789, -25.100000381469727]" #38
G = "[15.899999618530273, -84.4000015258789, -25.100000381469727]"
offset_C_ROOT = "[-34.100000381469727, -37.79999923706055, -58.29999923706055]" #62
C_ROOT = "[-24.100000381469727, -37.79999923706055, -58.29999923706055]"
offset_D = "[-34.399999618530273, -44.0, -58.29999923706055]" #58
D = "[-24.399999618530273, -44.0, -58.29999923706055]"
offset_E = "[-35.100000381469727, -52.099998474121094, -58.599998474121094]" # 53
E = "[-25.100000381469727, -52.099998474121094, -58.599998474121094]"
offset_F = "[-33.399999618530273, -66.0999984741211, -47.900001525878906] " # 43
F = "[-23.399999618530273, -66.0999984741211, -47.900001525878906] "
'''
# ---------- All Xylophone Notes
Notes = {
    'offset_C_First_Inv': '[27.600000381469727, -51.5, -43.29999923706055]',
    'C_First_Inv': '[17.600000381469727, -51.5, -43.29999923706055]',
    'offset_B': '[26.299999237060547, -59.0, -42.70000076293945]',
    'B': '[16.299999237060547, -59.0, -42.70000076293945]',
    'offset_A': '[25.300000190734863, -75.9000015258789, -28.0]',
    'A': '[15.300000190734863, -75.9000015258789, -28.0]',
    'offset_G': '[25.899999618530273, -84.4000015258789, -25.100000381469727]',
    'G': '[15.899999618530273, -84.4000015258789, -25.100000381469727]',
    'offset_C_Root': '[-34.100000381469727, -37.79999923706055, -58.29999923706055]',
    'C_Root': '[-24.100000381469727, -37.79999923706055, -58.29999923706055]',
    'offset_D': '[-34.399999618530273, -44.0, -58.29999923706055]',
    'D': '[-24.399999618530273, -44.0, -58.29999923706055]',
    'offset_E': '[-35.100000381469727, -52.099998474121094, -58.599998474121094]',
    'E': '[-25.100000381469727, -52.099998474121094, -58.599998474121094]',
    'offset_F': '[-33.399999618530273, -66.0999984741211, -47.900001525878906]',
    'F': '[-23.399999618530273, -66.0999984741211, -47.900001525878906]'
}


# ---------- Basket Case
Basket_Case = {
    0.0: ['G', 'offset_G'],
    4.5: ['F', 'offset_F'],
    8.3: ['E', 'offset_E'],
    12.1: ['F', 'offset_F'],
    15.9: ['G', 'offset_G'],
    20.4: ['B', 'offset_B'],
    24.2: ['C_First_Inv', 'offset_C_First_Inv'],
    28.0: ['B', 'offset_B'],
    31.8: ['A', 'offset_A'],
    35.6: ['G', 'offset_G'],
    39.4: ['G', 'offset_G'],
    43.9: ['B', 'offset_B'],
    47.4: ['C_First_Inv', 'offset_C_First_Inv'],
    51.2: ['B', 'offset_B'],
    55.0: ['A', 'offset_A'],
    58.8: ['G', 'offset_G'],
    62.6: ['G', 'offset_G'],
    66.4: ['G', 'offset_G'],
    70.2: ['G', 'offset_G'],
    74.0: ['B', 'offset_B'],
    78.5: ['C_First_Inv', 'offset_C_First_Inv'],
    82.3: ['B', 'offset_B'],
}

# ---------- Row The Boat
Row_the_Boat = {
    0.0: ['C_Root', 'offset_C_Root'],
    4.5: ['C_Root', 'offset_C_Root'],
    9.0: ['C_Root', 'offset_C_Root'],
    12.8: ['D', 'offset_D'],
    16.6: ['E', 'offset_E'],
    21.1: ['E', 'offset_E'],
    24.9: ['D', 'offset_D'],
    28.7: ['E', 'offset_E'],
    32.5: ['F', 'offset_F'],
    36.3: ['G', 'offset_G'],
    40.8: ['C_First_Inv', 'offset_C_First_Inv'],
    44.6: ['C_First_Inv', 'offset_C_First_Inv'],
    48.4: ['C_First_Inv', 'offset_C_First_Inv'],
    52.2: ['G', 'offset_G'],
    56.0: ['G', 'offset_G'],
    59.8: ['G', 'offset_G'],
    63.6: ['E', 'offset_E'],
    67.4: ['E', 'offset_E'],
    71.2: ['E', 'offset_E'],
    75.0: ['C_Root', 'offset_C_Root'],
    78.8: ['C_Root', 'offset_C_Root'],
    82.6: ['C_Root', 'offset_C_Root'],
    86.4: ['G', 'offset_G'],
    90.9: ['F', 'offset_F'],
    94.7: ['E', 'offset_E'],
    98.5: ['D', 'offset_D'],
    102.3: ['C_Root', 'offset_C_Root'],
}

# ---------- Star Wars Theme Song
Star_Wars ={
    0.0: ['C_Root', 'offset_C_Root'],
    4.5: ['G', 'offset_G'],
    9.0: ['F', 'offset_F'],
    12.8: ['E', 'offset_E'],
    16.6: ['D', 'offset_D'],
    20.4: ['C_First_Inv', 'offset_C_First_Inv'],
    24.9: ['G', 'offset_G'],
    29.4: ['F', 'offset_F'],
    33.2: ['E', 'offset_E'],
    37.0: ['D', 'offset_D'],
    40.8: ['C_First_Inv', 'offset_C_First_Inv'],
    45.3: ['G', 'offset_G'],
    49.8: ['F', 'offset_F'],
    53.6: ['E', 'offset_E'],
    57.4: ['F', 'offset_F'],
    61.2: ['D', 'offset_D'],
    65.7: ['G', 'offset_G'],
    69.5: ['G', 'offset_G'],
    73.3: ['C_Root', 'offset_C_Root'],
    77.8: ['G', 'offset_G'],
    82.3: ['F', 'offset_F'],
    86.1: ['E', 'offset_E'],
    89.9: ['D', 'offset_D'],
    93.7: ['C_First_Inv', 'offset_C_First_Inv'],
    98.2: ['G', 'offset_G'],
    102.7: ['F', 'offset_F'],
    106.5: ['E', 'offset_E'],
    110.3: ['D', 'offset_D'],
    114.1: ['C_First_Inv', 'offset_C_First_Inv'],
    118.6: ['G', 'offset_G'],
    123.1: ['F', 'offset_F'],
    126.9: ['E', 'offset_E'],
    130.7: ['F', 'offset_F'],
    134.5: ['D', 'offset_D'],
}

# -------- ML MODEL AND MELODY PATHS

model_path = "/home/ez/catkin_ws/src/tutorial_qt_motors/src/scripts/ML_KNN_dB_Model.joblib"

#melody = "/home/ez/catkin_ws/src/tutorial_qt_motors/User_Melody.wav"
melody = '/home/ez/User_Melody.wav'


# ---------- LISTS
#trim_samples = []
#ml_audio_data = []

# --------------------- MAIN SCRIPT

change_mot_speed("100")

get_ready("right_arm", r_pose1, r_pose2, r_pose3)
get_ready("left_arm",  l_pose1, l_pose2, l_pose3)

while True:
    print("Hello! Please select one of QT music modalities, by typing its respective number")
    print("")
    print("          1. Play a Song from Music Script")
    print("")
    print("          2. Recreate User - Played Melody")
    print("")
    print("          3. Exit")
    print("")

    user_input = input(" What is your choice?  --> ")
    
    if user_input == "1":
        print(" Great! Which song should QT play for you?")
        print("")
        print("          1. Basket Case ( Green Day )")
        print("")
        print("          2. Row The Boat")
        print("")
        print("          3. Star Wars Theme")
        print("")
        print("          4. Exit ")
        print("")
        user_input = input(" Please type your chosen number:   ")

        if user_input == "1":
            print(" Playing Basket Case ")
            #start = time.time() #rospy.time()

            play_from_script(Basket_Case, Notes)


            #end = time.time()
            #elapsed = end - start # Calculates the time the whole song took
            #print(elapsed)
            go_home('right_arm', Home_r)
            go_home('left_arm', Home_l)

        elif user_input == "2":
            print("Playing Row The Boat ... ")
            
            play_from_script(Row_the_Boat, Notes)
            
            go_home('right_arm', Home_r)
            go_home('left_arm', Home_l)

        elif user_input == "3":
            print("Playing Star Wars Theme Song ... ")
            
            play_from_script(Star_Wars, Notes)
            
            go_home('right_arm', Home_r)
            go_home('left_arm', Home_l)

        elif user_input == "4":
            print("Exiting...")
            get_ready("right_arm", r_pose3, r_pose2, r_pose1)
            get_ready("left_arm", l_pose3, l_pose2, l_pose1)
            break 

        else:
            print("Invalid input. Please enter one of the given numbers.")

    elif user_input == "2":
        print("Please get ready to play!")
        print("NOW!")

        trim_samples = []
        ml_audio_data = []
        # RECORD USER MELODY

        record_melody(8) #15

        raw, sr = librosa.load(melody) # Load melody with Librosa

        note_ft = librosa.stft(raw) # STFT of raw melody
        note_db = librosa.amplitude_to_db(np.abs(note_ft), ref = np.max) # Convert to dB

        trim_song_by_notes(raw, note_db, trim_samples) # Slice song to predict each note separately

        for trimmed in trim_samples:
            ft = librosa.stft(trimmed) # Short-time Fourier transform
            ft_db = librosa.amplitude_to_db(np.abs(ft), ref = np.max)
            ft_average = np.mean(np.abs(ft_db), axis = 1)
            ml_audio_data.append(ft_average)


        ml_audio_data = np.array(ml_audio_data)

        # MELODY LABELS ( for testing only )
        # labels = ["C_Root", "D", "E", "F", "G", "A", "B", "C_First_Inv",]

        X_test = ml_audio_data
        #y_test = labels

        load_model = joblib.load(model_path)

        prediction = load_model.predict(X_test)
        print(prediction)

        '''
        score = load_model.score(X_test, y_test)
        print("-- Accuracy:     ", score*100, '%')

        for h in range(len(prediction)):
            print(prediction[h], y_test[h])
        '''

        print("-- PROCESS TIME CPU:    ", time.process_time())


        for note in prediction:
            if note in ["C_First_Inv", "B", "A", "G"]:
                
                arm = "right_arm"
                offset = Notes[f"offset_{note}"]
            else:
                
                arm = "left_arm"
                offset = Notes[f"offset_{note}"]
            note = Notes[f"{note}"]
            play_note(arm, note, offset)
            
        go_home('right_arm', Home_r)
        go_home('left_arm', Home_l)
        
    elif user_input == "3":
        print("Exiting...")
        get_ready("right_arm", r_pose3, r_pose2, r_pose1)
        get_ready("left_arm", l_pose3, l_pose2, l_pose1)
        break
    else:
        print("Invalid input. Please enter one of the given numbers.")


